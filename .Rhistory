iterations
1:iterations
newdata <- data.frame(matrix(NA, nrow = nrow(x)*iterations, ncol = ncol(x)))
newdata
i=1
i=2
nrow(x)
2*i
i*nrow(x)
i*nrow(x) - nrow(x)
i*nrow(x) - nrow(x) + 1
i*nrow(x) - nrow(x) + 1: i * nrow(x)
(i*nrow(x) - nrow(x) + 1) : (i * nrow(x))
i=1
(i*nrow(x) - nrow(x) + 1) : (i * nrow(x))
i=3
(i*nrow(x) - nrow(x) + 1) : (i * nrow(x))
x
rand()
rand
runif(1)
?sample
sample(x[,1])
sample(x[,1], size = 1)
source('~/Code/DMMS/R/lm_causalfilter.R', echo=TRUE)
newdata
x
newdata
causal_probs
source('~/Code/DMMS/R/lm_causalfilter.R', echo=TRUE)
filter_check
rows
causalfilter
causalfilter[row, ] <- filter_check
causalfilter[row,]
source('~/Code/DMMS/R/lm_causalfilter.R', echo=TRUE)
new_data
causalfilter
source('~/Code/DMMS/R/lm_causalfilter.R', echo=TRUE)
new_data
causal_filter
x
ipred
libs
weights
time_series
ts
ts = time_series
time_series = ts[1:10,]
target
theta
causal_filter = TRUE
source('~/Code/DMMS/R/lm_causalfilter.R', echo=TRUE)
x
time_series
time_series = x
causal_filter
x
new_data
time_series = new_data
y
rep(y, 3)
times_series = cbind(rep(y,3), new_data)
time_series
times_series = cbind(rep(y,3), new_data)
time_series
rep(y,3)
new_data
cbind(rep(y,3), new_data)
time_series = cbind(rep(y,3), new_data)
time_series
times_series = NULL
time_series
colnames(time_series)[1]
colnames(time_series)[1] = "Y"
time_series
manual_block
# Names for the output sequential Jacobian
if (manual_block == TRUE) {
coeff_names <- sapply(colnames(time_series)[2:ncol(time_series)], function(x) paste("d", colnames(time_series)[1], "/d", x, sep =""))
} else {
coeff_names <-sapply(colnames(time_series), function(x) paste("d", colnames(time_series)[target], "/d", x, sep =""))
}
# Combine target time series at time t+1 with all time series at time t, unless block == TRUE
if (manual_block == TRUE) {
block_raw <- time_series
} else {
block_raw <- cbind(time_series[2:nrow(time_series), target], time_series[1:(nrow(time_series)-1), ])
}
# "All time series were normalized to have a mean of 0 and standard deviation of 1." - Deyle, May, Munch, and Sugihara
block <- as.data.frame(apply(block_raw, 2, function(x) (x-mean(x)) / (sd(x)+1e-5) )) # 1e-5 is added to prevent divide by zero errors
# Full library of time steps
lib <- 1:nrow(block)
# Full set of prediction time steps
pred <- 1:nrow(block)
# Output sequential Jacobian
if (manual_block == TRUE) {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series) - 1))
} else {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series)))
}
colnames(coeff) <- coeff_names
ipred = 1
# Target time point is excluded from the fitting procedure
libs = lib[-pred[ipred]]
# Calculate weights
q <- matrix(as.numeric(block[pred[ipred], 2:ncol(block)]), ncol = ncol(coeff), nrow = length(libs), byrow = TRUE)
q
time_series
pred[ipred]
block[1, 2:ncol(block)]
block
q
missing(caas)
libs
lib
pred
block
weights_filter <- matrix(1, nrow = nrow(block) - 1, ncol = ncol(block) - 1)
weights_filter
causal_filter
pred
ipred
q
# If a causal filter was supplied determine which data points will be included in calculating the weights for the linear models
if (missing(causal_filter)) {
weights_filter <- matrix(1, nrow = nrow(block) - 1, ncol = ncol(block) - 1)
} else {
weights_filter <- causal_filter[-pred[ipred], ]
}
weights_filter
q
q * weights_filter
block_filter <- block[libs, 2:ncol(block)] * weights_filter
q_filter <- q * weights_filter
block_filter
q_filter
distances <- sqrt(rowSums((block_filter - q_filter)^2))
distances
dbar <- mean(distances)
weights <- exp(-theta * distances / dbar)
weights
block
time_series
causal_filter
block
library("gpuR")
install.packages("gpuR")
library("gpuR")
x
y
time_series
causal_filter
if (manual_block == TRUE) {
coeff_names <- sapply(colnames(time_series)[2:ncol(time_series)], function(x) paste("d", colnames(time_series)[1], "/d", x, sep =""))
} else {
coeff_names <-sapply(colnames(time_series), function(x) paste("d", colnames(time_series)[target], "/d", x, sep =""))
}
# Combine target time series at time t+1 with all time series at time t, unless block == TRUE
if (manual_block == TRUE) {
block_raw <- time_series
} else {
block_raw <- cbind(time_series[2:nrow(time_series), target], time_series[1:(nrow(time_series)-1), ])
}
# "All time series were normalized to have a mean of 0 and standard deviation of 1." - Deyle, May, Munch, and Sugihara
block <- as.data.frame(apply(block_raw, 2, function(x) (x-mean(x)) / (sd(x)+1e-5) )) # 1e-5 is added to prevent divide by zero errors
# Full library of time steps
lib <- 1:nrow(block)
# Full set of prediction time steps
pred <- 1:nrow(block)
# Output sequential Jacobian
if (manual_block == TRUE) {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series) - 1))
} else {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series)))
}
colnames(coeff) <- coeff_names
ipred = 1
# Target time point is excluded from the fitting procedure
libs = lib[-pred[ipred]]
# If a causal filter was supplied determine which data points will be included in calculating the weights for the linear models
if (missing(causal_filter)) {
weights_filter <- matrix(1, nrow = nrow(block) - 1, ncol = ncol(block) - 1)
} else {
weights_filter <- causal_filter[-pred[ipred], ]
}
# Calculate weights
q <- matrix(as.numeric(block[pred[ipred], 2:ncol(block)]), ncol = ncol(coeff), nrow = length(libs), byrow = TRUE)
block_filter <- block[libs, 2:ncol(block)] * weights_filter
q_filter <- q * weights_filter
distances <- sqrt(rowSums((block_filter - q_filter)^2))
dbar <- mean(distances)
weights <- exp(-theta * distances / dbar)
# Regression using singular value decomposition and the calculated weights
y <- block[libs, 1]
x <- block[libs, 2:ncol(block)]
lm_svd <- function(y, x, weights, intercept = TRUE)
{
# Normalize weights
weights_normalized <- weights #/sum(weights)
# Add column of ones for the constant term in the linear model unless intercept = FALSE
if (intercept == TRUE) {
A <- cbind(1, (x * weights_normalized))
} else {
A <- x * weights_normalized
}
# Singular Value Decomposition
A_svd <- svd(A)
s <- A_svd$d
if (intercept == TRUE) {
s_inv <- matrix(0, nrow = (ncol(x)+1), ncol = (ncol(x)+1))
} else {
s_inv <- matrix(0, nrow = ncol(x), ncol = ncol(x))
}
for(i in seq_along(s)){
if(s[i] >= max(s) * 1e-5) { # Remove small singular values
s_inv[i, i] <- 1/s[i]
}
}
# Exponentially-weighted regression using singular value decomposition
coeff <- t(A_svd$v %*% s_inv %*% t(A_svd$u) %*% (weights_normalized * y))
if (intercept == TRUE) {
if (is.null(colnames(x)) == TRUE) {
colnames(coeff) <- c("Constant", colnames(data.frame(x)))
} else {
colnames(coeff) <- c("Constant", colnames(x))
}
} else {
if (is.null(colnames(x)) == TRUE) {
colnames(coeff) <- colnames(data.frame(x))
} else {
colnames(coeff) <- colnames(x)
}
}
return(coeff)
}
svd_fit <- lm_svd(y, x, weights)
svd_fit
# Names for the output sequential Jacobian
if (manual_block == TRUE) {
coeff_names <- sapply(colnames(time_series)[2:ncol(time_series)], function(x) paste("d", colnames(time_series)[1], "/d", x, sep =""))
} else {
coeff_names <-sapply(colnames(time_series), function(x) paste("d", colnames(time_series)[target], "/d", x, sep =""))
}
# Combine target time series at time t+1 with all time series at time t, unless block == TRUE
if (manual_block == TRUE) {
block_raw <- time_series
} else {
block_raw <- cbind(time_series[2:nrow(time_series), target], time_series[1:(nrow(time_series)-1), ])
}
# "All time series were normalized to have a mean of 0 and standard deviation of 1." - Deyle, May, Munch, and Sugihara
block <- as.data.frame(apply(block_raw, 2, function(x) (x-mean(x)) / (sd(x)+1e-5) )) # 1e-5 is added to prevent divide by zero errors
# Full library of time steps
lib <- 1:nrow(block)
# Full set of prediction time steps
pred <- 1:nrow(block)
# Output sequential Jacobian
if (manual_block == TRUE) {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series) - 1))
} else {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series)))
}
colnames(coeff) <- coeff_names
# Exponentially-weighted linear model for each time point from t to t_max-1
for (ipred in 1:length(pred)) {
# Target time point is excluded from the fitting procedure
libs = lib[-pred[ipred]]
# If a causal filter was supplied determine which data points will be included in calculating the weights for the linear models
if (missing(causal_filter)) {
weights_filter <- matrix(1, nrow = nrow(block) - 1, ncol = ncol(block) - 1)
} else {
weights_filter <- causal_filter[-pred[ipred], ]
}
# Calculate weights
q <- matrix(as.numeric(block[pred[ipred], 2:ncol(block)]), ncol = ncol(coeff), nrow = length(libs), byrow = TRUE)
block_filter <- block[libs, 2:ncol(block)] * weights_filter
q_filter <- q * weights_filter
distances <- sqrt(rowSums((block_filter - q_filter)^2))
dbar <- mean(distances)
weights <- exp(-theta * distances / dbar)
# Regression using singular value decomposition and the calculated weights
y <- block[libs, 1]
x <- block[libs, 2:ncol(block)]
# svd_fit <- DMMS::lm_svd(y, x, weights)
svd_fit <- lm_svd(y, x, weights)
# Add sequential Jacobians to the growing output, ignoring the constant term in the linear model
coeff[ipred, ] <- svd_fit[-1]
}
# Combine output with the observation dates if supplied, or a simple counter ID if not
if (missing(dates)) {
coeff <- cbind(pred, coeff)
colnames(coeff)[1] <- "ID"
} else {
coeff <- cbind(dates[1:(length(dates)-1)], coeff)
colnames(coeff)[1] <- "Date"
}
coeff
coeff <- cbind(pred, coeff)
colnames(coeff)[1] <- "ID"
coeff
nrow(time_series)
x
causal_iterations = 3
causal_filter
data_size <- nrow(time_series)/causal_iterations
data_size
coeff
causal_iterations
# Names for the output sequential Jacobian
if (manual_block == TRUE) {
coeff_names <- sapply(colnames(time_series)[2:ncol(time_series)], function(x) paste("d", colnames(time_series)[1], "/d", x, sep =""))
} else {
coeff_names <-sapply(colnames(time_series), function(x) paste("d", colnames(time_series)[target], "/d", x, sep =""))
}
# Combine target time series at time t+1 with all time series at time t, unless block == TRUE
if (manual_block == TRUE) {
block_raw <- time_series
} else {
block_raw <- cbind(time_series[2:nrow(time_series), target], time_series[1:(nrow(time_series)-1), ])
}
# "All time series were normalized to have a mean of 0 and standard deviation of 1." - Deyle, May, Munch, and Sugihara
block <- as.data.frame(apply(block_raw, 2, function(x) (x-mean(x)) / (sd(x)+1e-5) )) # 1e-5 is added to prevent divide by zero errors
# Full library of time steps
lib <- 1:nrow(block)
# Full set of prediction time steps
pred <- 1:nrow(block)
# Output sequential Jacobian
if (manual_block == TRUE) {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series) - 1))
} else {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series)))
}
colnames(coeff) <- coeff_names
# Exponentially-weighted linear model for each time point from t to t_max-1
for (ipred in 1:length(pred)) {
# Target time point is excluded from the fitting procedure
libs = lib[-pred[ipred]]
# If a causal filter was supplied determine which data points will be included in calculating the weights for the linear models
if (missing(causal_filter)) {
weights_filter <- matrix(1, nrow = nrow(block) - 1, ncol = ncol(block) - 1)
} else {
weights_filter <- causal_filter[-pred[ipred], ]
}
# Calculate weights
q <- matrix(as.numeric(block[pred[ipred], 2:ncol(block)]), ncol = ncol(coeff), nrow = length(libs), byrow = TRUE)
block_filter <- block[libs, 2:ncol(block)] * weights_filter
q_filter <- q * weights_filter
distances <- sqrt(rowSums((block_filter - q_filter)^2))
dbar <- mean(distances)
weights <- exp(-theta * distances / dbar)
# Regression using singular value decomposition and the calculated weights
y <- block[libs, 1]
x <- block[libs, 2:ncol(block)]
# svd_fit <- DMMS::lm_svd(y, x, weights)
svd_fit <- lm_svd(y, x, weights)
# Add sequential Jacobians to the growing output, ignoring the constant term in the linear model
coeff[ipred, ] <- svd_fit[-1]
}
# Needed to find the summarized Jacobians for each true data point if causal filtering was used
if (missing(causal_filter)) {
} else {
data_size <- nrow(time_series)/causal_iterations
}
coeff
coeff_full <- coeff
coeff <- data.frame(matrix(NA, nrow = data_size, ncol = ncol(coeff)))
coeff
coeff_full
colnames(coeff) <- colnames(coeff_full)
coeff
?seq
seq(from = 1, to = 30, by = 10)
seq(from = 2, to = 30, by = 10)
seq(from = 6, to = 30, by = 10)
r = 2
subset <- seq(from = r, to = nrow(coeff_full), by = data_size)
subset
coeff_full[subset,]
mean(coeff_full[subset,])
colmean(coeff_full[subset,])
colmeans(coeff_full[subset,])
apply(coeff_full[subset,], 2, mean)
# Names for the output sequential Jacobian
if (manual_block == TRUE) {
coeff_names <- sapply(colnames(time_series)[2:ncol(time_series)], function(x) paste("d", colnames(time_series)[1], "/d", x, sep =""))
} else {
coeff_names <-sapply(colnames(time_series), function(x) paste("d", colnames(time_series)[target], "/d", x, sep =""))
}
# Combine target time series at time t+1 with all time series at time t, unless block == TRUE
if (manual_block == TRUE) {
block_raw <- time_series
} else {
block_raw <- cbind(time_series[2:nrow(time_series), target], time_series[1:(nrow(time_series)-1), ])
}
# "All time series were normalized to have a mean of 0 and standard deviation of 1." - Deyle, May, Munch, and Sugihara
block <- as.data.frame(apply(block_raw, 2, function(x) (x-mean(x)) / (sd(x)+1e-5) )) # 1e-5 is added to prevent divide by zero errors
# Full library of time steps
lib <- 1:nrow(block)
# Full set of prediction time steps
pred <- 1:nrow(block)
# Output sequential Jacobian
if (manual_block == TRUE) {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series) - 1))
} else {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series)))
}
colnames(coeff) <- coeff_names
# Exponentially-weighted linear model for each time point from t to t_max-1
for (ipred in 1:length(pred)) {
# Target time point is excluded from the fitting procedure
libs = lib[-pred[ipred]]
# If a causal filter was supplied determine which data points will be included in calculating the weights for the linear models
if (missing(causal_filter)) {
weights_filter <- matrix(1, nrow = nrow(block) - 1, ncol = ncol(block) - 1)
} else {
weights_filter <- causal_filter[-pred[ipred], ]
}
# Calculate weights
q <- matrix(as.numeric(block[pred[ipred], 2:ncol(block)]), ncol = ncol(coeff), nrow = length(libs), byrow = TRUE)
block_filter <- block[libs, 2:ncol(block)] * weights_filter
q_filter <- q * weights_filter
distances <- sqrt(rowSums((block_filter - q_filter)^2))
dbar <- mean(distances)
weights <- exp(-theta * distances / dbar)
# Regression using singular value decomposition and the calculated weights
y <- block[libs, 1]
x <- block[libs, 2:ncol(block)]
# svd_fit <- DMMS::lm_svd(y, x, weights)
svd_fit <- lm_svd(y, x, weights)
# Add sequential Jacobians to the growing output, ignoring the constant term in the linear model
coeff[ipred, ] <- svd_fit[-1]
}
data_size <- nrow(time_series)/causal_iterations
coeff_full <- coeff
coeff <- data.frame(matrix(NA, nrow = data_size, ncol = ncol(coeff)))
colnames(coeff) <- colnames(coeff_full)
for (r in 1:data_size) {
subset <- seq(from = r, to = nrow(coeff_full), by = data_size)
coeff[r, ] <- apply(coeff_full[subset,], MARGIN = 2, FUN = mean)
}
coeff <- cbind(pred, coeff)
colnames(coeff)[1] <- "ID"
coeff
pred
# Names for the output sequential Jacobian
if (manual_block == TRUE) {
coeff_names <- sapply(colnames(time_series)[2:ncol(time_series)], function(x) paste("d", colnames(time_series)[1], "/d", x, sep =""))
} else {
coeff_names <-sapply(colnames(time_series), function(x) paste("d", colnames(time_series)[target], "/d", x, sep =""))
}
# Combine target time series at time t+1 with all time series at time t, unless block == TRUE
if (manual_block == TRUE) {
block_raw <- time_series
} else {
block_raw <- cbind(time_series[2:nrow(time_series), target], time_series[1:(nrow(time_series)-1), ])
}
# "All time series were normalized to have a mean of 0 and standard deviation of 1." - Deyle, May, Munch, and Sugihara
block <- as.data.frame(apply(block_raw, 2, function(x) (x-mean(x)) / (sd(x)+1e-5) )) # 1e-5 is added to prevent divide by zero errors
# Full library of time steps
lib <- 1:nrow(block)
# Full set of prediction time steps
pred <- 1:nrow(block)
# Output sequential Jacobian
if (manual_block == TRUE) {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series) - 1))
} else {
coeff <- as.data.frame(matrix(0, nrow = length(pred), ncol = ncol(time_series)))
}
colnames(coeff) <- coeff_names
# Exponentially-weighted linear model for each time point from t to t_max-1
for (ipred in 1:length(pred)) {
# Target time point is excluded from the fitting procedure
libs = lib[-pred[ipred]]
# If a causal filter was supplied determine which data points will be included in calculating the weights for the linear models
if (missing(causal_filter)) {
weights_filter <- matrix(1, nrow = nrow(block) - 1, ncol = ncol(block) - 1)
} else {
weights_filter <- causal_filter[-pred[ipred], ]
}
# Calculate weights
q <- matrix(as.numeric(block[pred[ipred], 2:ncol(block)]), ncol = ncol(coeff), nrow = length(libs), byrow = TRUE)
block_filter <- block[libs, 2:ncol(block)] * weights_filter
q_filter <- q * weights_filter
distances <- sqrt(rowSums((block_filter - q_filter)^2))
dbar <- mean(distances)
weights <- exp(-theta * distances / dbar)
# Regression using singular value decomposition and the calculated weights
y <- block[libs, 1]
x <- block[libs, 2:ncol(block)]
# svd_fit <- DMMS::lm_svd(y, x, weights)
svd_fit <- lm_svd(y, x, weights)
# Add sequential Jacobians to the growing output, ignoring the constant term in the linear model
coeff[ipred, ] <- svd_fit[-1]
}
data_size <- nrow(time_series)/causal_iterations
coeff_full <- coeff
coeff <- data.frame(matrix(NA, nrow = data_size, ncol = ncol(coeff)))
colnames(coeff) <- colnames(coeff_full)
for (r in 1:data_size) {
subset <- seq(from = r, to = nrow(coeff_full), by = data_size)
coeff[r, ] <- apply(coeff_full[subset,], MARGIN = 2, FUN = mean)
}
coeff <- cbind(1:data_size, coeff)
colnames(coeff)[1] <- "ID"
coeff
devtools::document()
devtools::document()
devtools::document()
time_series
time_series[2:nrow(time_series), 1]
time_series[-1, 1]
time_series[-nrow(time_series), 1]
